{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Building a Transformer with PyTorch**\n",
        "### Crearemos un modelo de Transformer utilizando PyTorch, una potente herramienta de aprendizaje automático moderno.\n",
        "\n",
        "https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch"
      ],
      "metadata": {
        "id": "8Sk8ZNj4ziX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57yn15j-ZKOr",
        "outputId": "8687743d-0b91-4025-915c-8668d0465d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy"
      ],
      "metadata": {
        "id": "XlCYySW5ZXn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Los parametros de multiple atencion."
      ],
      "metadata": {
        "id": "t7OeN93nZrOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # Se asegura de que la dimensión del modelo (d_model) sea divisible por el número de cabezas.\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        # Inicializar dimensiones\n",
        "        self.d_model = d_model # Dimension del modelo\n",
        "        self.num_heads = num_heads # Numero de cabezas\n",
        "        self.d_k = d_model // num_heads # Dimensión de las claves, consulta y valores de cada cabeza\n",
        "\n",
        "        # Capas lineales para transformar entradas.\n",
        "        self.W_q = nn.Linear(d_model, d_model) # Transformación de consultas\n",
        "        self.W_k = nn.Linear(d_model, d_model) # Transformación de claves\n",
        "        self.W_v = nn.Linear(d_model, d_model) # Transformacion de Valores\n",
        "        self.W_o = nn.Linear(d_model, d_model) # Transformacion de Salida\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        # Calcula puntuaciones de atención\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # Aplica máscaras si se proporcionan (útil para evitar que se preste atención a ciertas partes)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Se aplica Softmax para obtener probabilidades de atención\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Multiplicar por valores para obtener el resultado final.\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        # Cambia la forma de la entrada para que num_heads genere atención para múltiples cabezas\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        # Combine las múltiples cabezas nuevamente a su forma original.\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        # Aplicar transformaciones lineales y cabezas divididas.\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        # Da atención a productos escalados\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "        # Combina las cabezas y aplica la transformación de salida.\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output"
      ],
      "metadata": {
        "id": "8-v1HihhZwQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmo FeedForward"
      ],
      "metadata": {
        "id": "OcAXEq0pag6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "\n",
        "        # Define dos capas lineales para la transformación anticipada.\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)  # Capa 1 completamente conectada\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)  # Capa 2 completamente conectada\n",
        "\n",
        "        # Función de activación para introducir no linealidad.\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Paso directo a través de la red feedforward:\n",
        "         # 1. Aplicar la primera capa lineal (fc1)\n",
        "         # 2. Aplicar la función de activación Rectified Linear Unit (ReLU)\n",
        "         # 3. Aplicar la segunda capa lineal (fc2)\n",
        "        return self.fc2(self.relu(self.fc1(x)))"
      ],
      "metadata": {
        "id": "k5qpC3jHakWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Posicionamiento en el codificador"
      ],
      "metadata": {
        "id": "lCsrq7M8a5Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # Inicializa una matriz de codificación posicional.\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "\n",
        "        # Crea un tensor de posición con valores [0, 1, 2, ..., max_seq_length-1]\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # Calcula div_term utilizado para el cálculo de senos y cosenos\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        # Calcula los componentes seno y coseno de la codificación posicional.\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Registra la codificación posicional como un búfer (no entrenable)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Agrega la codificación posicional al tensor de entrada a lo largo de la dimensión de la secuencia\n",
        "        return x + self.pe[:, :x.size(1)]"
      ],
      "metadata": {
        "id": "jPAVzNG1a5Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codificador"
      ],
      "metadata": {
        "id": "KixMKfSJbc4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        # Capa de autoatención de múltiples cabezales\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        # Capa FeedForward según la posición\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "\n",
        "        # Normalización de capas tanto para atención como para FeedForward\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Calculo de \"abandono\" por regularización\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Autoatención de múltiples cabezales: aplica el mecanismo de atención a la entrada\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "\n",
        "        # Conexión residual y normalización de capas (Subcapa 1).\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Feedforward por posición: aplica la transformación feedforward\n",
        "        ff_output = self.feed_forward(x)\n",
        "\n",
        "        # Conexión residual y normalización de capas (Subcapa 2).\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "_mS2rXLIbf5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decodificador"
      ],
      "metadata": {
        "id": "lfq-8nuhb38-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Capa de autoatención para la secuencia objetivo\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        # Capa de atención cruzada (atención codificador-decodificador)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        # Capa FeedForward según la posición\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "\n",
        "        # Normalización de capas para las tres subcapas.\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Calculo de \"abandono\" por regularización\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        # Capa de autoatención para la secuencia objetivo\n",
        "        self_attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "\n",
        "        # Conexión residual y normalización de capas para la autoatención\n",
        "        x = self.norm1(x + self.dropout(self_attn_output))\n",
        "\n",
        "        # Capa de atención cruzada (atención codificador-decodificador aplicada)\n",
        "        cross_attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "\n",
        "        x = self.norm2(x + self.dropout(cross_attn_output))\n",
        "\n",
        "        ff_output = self.feed_forward(x)\n",
        "\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "bsG0G2w6b6CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformador"
      ],
      "metadata": {
        "id": "4x3ufJ2xcFCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        # Incrustaciones de origen y destino: convierte los ID de token en vectores.\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # Codificación posicional: agrega información posicional a las incrustaciones.\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        # Capas de codificador y decodificador apiladas durante el tiempo determinado en 'num_layers'.\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        # Capa lineal final: mapas desde d_model hasta el tamaño del vocabulario objetivo.\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "        # Calculo de \"abandono\" por regularización, evita el overfitting\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        # Máscara de origen: enmascara los valores acolchados (donde el ID del token es 0).\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Máscara de destino: hace lo mismo para el objetivo, pero también enmascara valores futuros para garantizar un comportamiento autorregresivo.\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Genera máscaras para secuencias de origen y de destino.\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "\n",
        "        # Aplicar incrustaciones y codificaciones posicionales.\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        # Pasa la secuencia fuente a través de las capas del codificador.\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        # Pasa la secuencia de destino y la salida del codificador a través de las capas del decodificador.\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        # Asigna la salida del decodificador al tamaño del vocabulario objetivo.\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "8l9XTcbdcHbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Entrenamiento con informacion generada de forma aleatoria***\n",
        "\n",
        "Solo con propositos de prueba, no es recomendable para cualquier operacion que deseemos hacer con el Transformer."
      ],
      "metadata": {
        "id": "4yC5u7YGcYul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Definimos hiperparámetros, todos crean \"palabras\" de forma aleatoria\n",
        "src_vocab_size = 5000\n",
        "tgt_vocab_size = 5000\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "d_ff = 2048\n",
        "max_seq_length = 100\n",
        "dropout = 0.1\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "# Definimos el modelo de transformador que ya desarrollamos\n",
        "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
        "\n",
        "# Define la función de pérdida y el optimizador.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=learning_rate)\n",
        "\n",
        "# Genera datos de muestra aleatorios (De ser posible se pueden reemplazar con datos reales)\n",
        "src_data = torch.randint(1, src_vocab_size, (batch_size, max_seq_length))  # (batch_size, seq_length)\n",
        "tgt_data = torch.randint(1, tgt_vocab_size, (batch_size, max_seq_length))  # (batch_size, seq_length)\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "for epoch in range(num_epochs):\n",
        "    transformer.train()  # Establece el modelo en modo de entrenamiento.\n",
        "\n",
        "    # Itera a través de lotes\n",
        "    for batch_start in range(0, len(src_data), batch_size):\n",
        "        # Obtiene un lote de datos de origen y de destino.\n",
        "        src_batch = src_data[batch_start:batch_start+batch_size]\n",
        "        tgt_batch = tgt_data[batch_start:batch_start+batch_size]\n",
        "\n",
        "        # Pone los gradientes en cero.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pase adelantado\n",
        "        output = transformer(src_batch, tgt_batch[:, :-1])  # Exclude the last token in target\n",
        "\n",
        "        # Calculo de la perdida\n",
        "        loss = criterion(output.view(-1, tgt_vocab_size), tgt_batch[:, 1:].contiguous().view(-1))\n",
        "\n",
        "        # Propagación hacia atrás\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Pérdida de impresión por cada \"epoch\".\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "C3H6zfDFcedF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04a78b2-3b17-4f5a-8379-fb4b4975cc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] Loss: 8.681730270385742\n",
            "Epoch [2/50] Loss: 8.5138521194458\n",
            "Epoch [3/50] Loss: 8.263517379760742\n",
            "Epoch [4/50] Loss: 8.744540214538574\n",
            "Epoch [5/50] Loss: 8.185982704162598\n",
            "Epoch [6/50] Loss: 8.140958786010742\n",
            "Epoch [7/50] Loss: 8.07398796081543\n",
            "Epoch [8/50] Loss: 7.890829563140869\n",
            "Epoch [9/50] Loss: 7.7089080810546875\n",
            "Epoch [10/50] Loss: 8.014005661010742\n",
            "Epoch [11/50] Loss: 7.812922954559326\n",
            "Epoch [12/50] Loss: 7.4533233642578125\n",
            "Epoch [13/50] Loss: 7.65604829788208\n",
            "Epoch [14/50] Loss: 7.314331531524658\n",
            "Epoch [15/50] Loss: 7.4651875495910645\n",
            "Epoch [16/50] Loss: 7.060393810272217\n",
            "Epoch [17/50] Loss: 6.679470062255859\n",
            "Epoch [18/50] Loss: 6.681331157684326\n",
            "Epoch [19/50] Loss: 6.412799835205078\n",
            "Epoch [20/50] Loss: 6.313271999359131\n",
            "Epoch [21/50] Loss: 5.993490219116211\n",
            "Epoch [22/50] Loss: 6.005606174468994\n",
            "Epoch [23/50] Loss: 5.754429817199707\n",
            "Epoch [24/50] Loss: 5.888615608215332\n",
            "Epoch [25/50] Loss: 5.1952738761901855\n",
            "Epoch [26/50] Loss: 5.019556045532227\n",
            "Epoch [27/50] Loss: 4.595293045043945\n",
            "Epoch [28/50] Loss: 4.359991073608398\n",
            "Epoch [29/50] Loss: 4.263702392578125\n",
            "Epoch [30/50] Loss: 3.9968748092651367\n",
            "Epoch [31/50] Loss: 3.715385675430298\n",
            "Epoch [32/50] Loss: 3.3535521030426025\n",
            "Epoch [33/50] Loss: 3.279010772705078\n",
            "Epoch [34/50] Loss: 3.1017096042633057\n",
            "Epoch [35/50] Loss: 2.632963180541992\n",
            "Epoch [36/50] Loss: 2.3130292892456055\n",
            "Epoch [37/50] Loss: 2.0316832065582275\n",
            "Epoch [38/50] Loss: 1.7755146026611328\n",
            "Epoch [39/50] Loss: 1.5248819589614868\n",
            "Epoch [40/50] Loss: 1.337227463722229\n",
            "Epoch [41/50] Loss: 1.1481859683990479\n",
            "Epoch [42/50] Loss: 1.0060182809829712\n",
            "Epoch [43/50] Loss: 0.9526737928390503\n",
            "Epoch [44/50] Loss: 0.735831081867218\n",
            "Epoch [45/50] Loss: 0.6454548835754395\n",
            "Epoch [46/50] Loss: 0.5210620760917664\n",
            "Epoch [47/50] Loss: 0.44845050573349\n",
            "Epoch [48/50] Loss: 0.37378832697868347\n",
            "Epoch [49/50] Loss: 0.311136931180954\n",
            "Epoch [50/50] Loss: 0.26229631900787354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Dandole Proposito: Traduccion del Ingles al Español.***\n",
        "\n",
        "Viendo que no se presento ningun inconveniente entrenandolo con parametros aleatorios, procederemos a darle un proposito con el que podamos interactuar."
      ],
      "metadata": {
        "id": "gX-_heqwJQxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"\n",
        "\n",
        "# Cargar datos\n",
        "with open(text_file, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().strip().split('\\n')\n",
        "    sentence_pairs = [line.split('\\t') for line in lines]\n",
        "\n",
        "# Dividir datos en partes de inglés y español\n",
        "english_sentences, spanish_sentences = zip(*sentence_pairs)\n",
        "\n",
        "# Dividir datos en conjuntos de entrenamiento, validación y prueba.\n",
        "data_size = len(english_sentences)\n",
        "train_size = int(0.8 * data_size)\n",
        "valid_size = int(0.1 * data_size)\n",
        "\n",
        "english_train, english_valid, english_test = english_sentences[:train_size], english_sentences[train_size:train_size+valid_size], english_sentences[train_size+valid_size:]\n",
        "spanish_train, spanish_valid, spanish_test = spanish_sentences[:train_size], spanish_sentences[train_size:train_size+valid_size], spanish_sentences[train_size+valid_size:]"
      ],
      "metadata": {
        "id": "cc8ekfTLJQaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Vocabulario y codificación de enteros\n",
        "\n",
        "def build_vocab(sentences, specials=('<pad>', '<sos>', '<eos>', '<unk>')):\n",
        "    # Aplana la lista de oraciones y cuenta las ocurrencias.\n",
        "\n",
        "    word_freq = Counter(token for sentence in sentences for token in sentence)\n",
        "\n",
        "    # Ordena por frecuencia y luego lexicográficamente\n",
        "\n",
        "    ordered_vocab = [pair[0] for pair in word_freq.most_common()]\n",
        "    vocab = tuple(specials) + tuple(ordered_vocab)\n",
        "    stoi = {word: i for i, word in enumerate(vocab)}\n",
        "    return vocab, stoi\n",
        "\n",
        "english_vocab, english_stoi = build_vocab(english_train)\n",
        "spanish_vocab, spanish_stoi = build_vocab(spanish_train)"
      ],
      "metadata": {
        "id": "C3uev1PzKTN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizacion\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize(sentences, language=\"english\"):\n",
        "    return [word_tokenize(sentence.lower(), language=language) for sentence in sentences]\n",
        "\n",
        "english_train_tok = tokenize(english_train)\n",
        "english_valid_tok = tokenize(english_valid)\n",
        "english_test_tok = tokenize(english_test)\n",
        "\n",
        "spanish_train_tok = tokenize(spanish_train, language=\"spanish\")\n",
        "spanish_valid_tok = tokenize(spanish_valid, language=\"spanish\")\n",
        "spanish_test_tok = tokenize(spanish_test, language=\"spanish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3D-82uwLKl6",
        "outputId": "d636ad02-5536-4329-a661-a031b79d419f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vocabularios\n",
        "\n",
        "english_vocab, english_stoi = build_vocab(english_train_tok)\n",
        "spanish_vocab, spanish_stoi = build_vocab(spanish_train_tok)"
      ],
      "metadata": {
        "id": "4CxF1zWHASnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(sentences, stoi):\n",
        "    sos_index = stoi['<sos>']\n",
        "    eos_index = stoi['<eos>']\n",
        "    unk_index = stoi['<unk>']\n",
        "\n",
        "    encoded_sentences = []\n",
        "    for sentence in sentences:\n",
        "        encoded_sentence = [sos_index] + [stoi.get(token, unk_index) for token in sentence] + [eos_index]\n",
        "        encoded_sentences.append(encoded_sentence)\n",
        "\n",
        "        # Debugging problematic sentence:\n",
        "        if max(encoded_sentence) >= len(stoi):\n",
        "            print(\"Problematic sentence:\", sentence)\n",
        "            print(\"Encoded:\", encoded_sentence)\n",
        "\n",
        "    return encoded_sentences\n",
        "\n",
        "english_train_enc = encode(english_train_tok, english_stoi)\n",
        "english_valid_enc = encode(english_valid_tok, english_stoi)\n",
        "english_test_enc = encode(english_test_tok, english_stoi)\n",
        "\n",
        "spanish_train_enc = encode(spanish_train_tok, spanish_stoi)\n",
        "spanish_valid_enc = encode(spanish_valid_tok, spanish_stoi)\n",
        "spanish_test_enc = encode(spanish_test_tok, spanish_stoi)"
      ],
      "metadata": {
        "id": "iDckWeeqCRWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_sentences = [item[\"src\"] for item in batch]\n",
        "    tgt_sentences = [item[\"tgt\"] for item in batch]\n",
        "\n",
        "    # Pad sequences for this batch\n",
        "    src_sentences_padded = torch.nn.utils.rnn.pad_sequence(src_sentences, batch_first=True, padding_value=0)\n",
        "    tgt_sentences_padded = torch.nn.utils.rnn.pad_sequence(tgt_sentences, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {\"src\": src_sentences_padded, \"tgt\": tgt_sentences_padded}\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, tgt_sentences):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.tgt_sentences = tgt_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            \"src\": torch.tensor(self.src_sentences[index], dtype=torch.long),\n",
        "            \"tgt\": torch.tensor(self.tgt_sentences[index], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Creating datasets\n",
        "train_dataset = TranslationDataset(english_train_enc, spanish_train_enc)\n",
        "valid_dataset = TranslationDataset(english_valid_enc, spanish_valid_enc)\n",
        "test_dataset = TranslationDataset(english_test_enc, spanish_test_enc)\n",
        "\n",
        "# Creating dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "gc75PUkSCZR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamaño de los datasets\n",
        "\n",
        "print(f\"Size of training dataset: {len(train_dataset)}\")\n",
        "print(f\"Size of validation dataset: {len(valid_dataset)}\")\n",
        "print(f\"Size of test dataset: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rU9SoAanrqt",
        "outputId": "b4a7ffa7-a7b0-4c51-dc34-8a279ee6d763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training dataset: 95171\n",
            "Size of validation dataset: 11896\n",
            "Size of test dataset: 11897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(english_vocab)\n",
        "tgt_vocab_size = len(spanish_vocab)\n",
        "\n",
        "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # 0 is <pad>\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "transformer.train()\n",
        "\n",
        "for epoch in range(1):\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        src, tgt = batch[\"src\"], batch[\"tgt\"]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = transformer(src, tgt[:, :-1])\n",
        "        loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt[:, 1:].contiguous().view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVgHmLJEFSVF",
        "outputId": "979842fe-7237-4ded-8da6-a6f005f660d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 3.311071655682979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluemos el esfuerzo**\n",
        "\n",
        "Tomo 2h17m31s entrenar solo un epoch de este modelo... mas computo requerido."
      ],
      "metadata": {
        "id": "wqdwPjXkm-sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            src, tgt = batch[\"src\"], batch[\"tgt\"]\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            tgt = tgt[:, 1:].contiguous().view(-1)\n",
        "            loss = criterion(output, tgt)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "test_loss = evaluate(transformer, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgHe6Q97nNGf",
        "outputId": "0a2a6bb6-54b4-4477-bcb3-b9adc0cc450a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.8270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokeniza oraciones y las convierte en tokens numéricos.\n",
        "    tokens = [token.text.lower() for token in spacy_eng(sentence)]\n",
        "    tokens = [src_field[\"<sos>\"]] + tokens + [src_field[\"<eos>\"]]\n",
        "    src_indexes = [src_field.get(token, src_field[\"<unk>\"]) for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # Crear un tensor objetivo vacío\n",
        "    trg_indexes = [trg_field[\"<sos>\"]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(max_len):\n",
        "            trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "            output = model(src_tensor, trg_tensor)\n",
        "            pred_token = output.argmax(2)[:, -1].item()\n",
        "            trg_indexes.append(pred_token)\n",
        "\n",
        "            # Deja de predecir si se alcanza el token de final de oración\n",
        "            if pred_token == trg_field[\"<eos>\"]:\n",
        "                break\n",
        "\n",
        "    trg_tokens = [list(trg_field.keys())[i] for i in trg_indexes]\n",
        "\n",
        "    # Devuelve la frase traducida (sin tokens <sos> y <eos>)\n",
        "    return trg_tokens[1:-1]\n",
        "\n",
        "# Prueba\n",
        "src_sentence = \"I love machine learning.\"\n",
        "translation = translate_sentence(src_sentence, english_stoi, spanish_stoi, transformer, device)\n",
        "print(\"Source Sentence:\", src_sentence)\n",
        "print(\"Translated Sentence:\", ' '.join(translation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilw6DWRPpglS",
        "outputId": "e3c2b73a-ba96-4a30-e607-f8d6fa3c9a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Sentence: I love machine learning.\n",
            "Translated Sentence: me encanta el amor a las dos y yo .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitivamente, mas computo, no hay suficiente maquina, no es en broma que para entrenar cualquier forma de maquina inteligente se requiere mucho mas CPU/GPU."
      ],
      "metadata": {
        "id": "T2oIw9GrroA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_tokenized_sentence(tokens, src_field, trg_field, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # Convierte a tokens numéricos y agregue <sos> y <eos>\n",
        "    tokens = [src_field[\"<sos>\"]] + tokens + [src_field[\"<eos>\"]]\n",
        "    src_indexes = [src_field.get(token, src_field[\"<unk>\"]) for token in tokens]\n",
        "\n",
        "    # Se convierte a tensor y agrega dimensión por lotes\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # Iniciar la traducción con el token <sos>\n",
        "    trg_indexes = [trg_field[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(src_tensor, trg_tensor)\n",
        "        pred_token = output.argmax(2)[:, -1].item()\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    # Convierte los índices de la traducción a palabras.\n",
        "    trg_tokens = [list(trg_field.keys())[list(trg_field.values()).index(i)] for i in trg_indexes]\n",
        "\n",
        "    # Remueve los tokens <sos> y <eos>\n",
        "    return trg_tokens[1:-1]"
      ],
      "metadata": {
        "id": "-ZU50lKislwb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence = [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "translation = translate_tokenized_sentence(tokenized_sentence, english_stoi, spanish_stoi, transformer, device)\n",
        "print(\"Tokenized Source Sentence:\", tokenized_sentence)\n",
        "print(\"Translated Sentence:\", ' '.join(translation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWtXrWEDtF_S",
        "outputId": "cf5871c8-e620-476a-e131-50316f641177"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Source Sentence: ['i', 'love', 'machine', 'learning']\n",
            "Translated Sentence: me encanta el amor a las mujeres me encanta .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sin Comentarios."
      ],
      "metadata": {
        "id": "3yMKz6QOtKFR"
      }
    }
  ]
}